{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52e8b2ea",
   "metadata": {},
   "source": [
    "# Summarising YouTube video transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf061fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from IPython.display import display, HTML, Markdown\n",
    "from pprint import pprint\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4cf552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import OpenAICallbackHandler\n",
    "\n",
    "totals_cb = OpenAICallbackHandler()\n",
    "\n",
    "print(totals_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754ebc05-3db7-4f65-8c31-c9b4c98d58fb",
   "metadata": {},
   "source": [
    "### YouTube videos used as examples:\n",
    "\n",
    "- [Yann LeCun and Andrew Ng: Why the 6-month AI Pause is a Bad Idea](https://www.youtube.com/watch?v=BY9KV8uCtj4)\n",
    "- [OpenAI CEO Sam Altman on the Future of AI](https://www.youtube.com/watch?v=A5uMNMAWi3E)\n",
    "- [Chat with OpenAI CEO and and Co-founder Sam Altman, and Chief Scientist Ilya Sutskever](https://www.youtube.com/watch?v=mC-0XqTAeMQ)\n",
    "- [The Godfather in Conversation: Why Geoffrey Hinton is worried about the future of AI](https://www.youtube.com/watch?v=-9cW4Gcn5WY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3a30f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "\n",
    "# YouTubeLoder uses 'youtube-transcript-api' library\n",
    "# https://github.com/jdepoix/youtube-transcript-api\n",
    "\n",
    "videos=[\n",
    "    \"https://www.youtube.com/watch?v=BY9KV8uCtj4\", # total tokens used - ca. 8k\n",
    "    \"https://www.youtube.com/watch?v=A5uMNMAWi3E\", # total tokens used - ca. 8k\n",
    "    \"https://www.youtube.com/watch?v=mC-0XqTAeMQ\", # total tokens used - ca. 11k\n",
    "    \"https://www.youtube.com/watch?v=-9cW4Gcn5WY\", # total tokens used - ca. 13k\n",
    "]\n",
    "\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    videos[0],\n",
    "    language=[\"en\"],\n",
    "    translation=\"en\",\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"Document has {len(docs)} pages\\n\")\n",
    "pprint(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c49725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "total_tokens = 0\n",
    "for n, page in enumerate(docs):\n",
    "    tokens = llm.get_num_tokens(page.page_content)\n",
    "    total_tokens += tokens\n",
    "    print(f\"Page {n+1:2d}: {tokens:>}\")\n",
    "    \n",
    "print(f\"Total number of tokens in document: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3080ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "token_splitter = TokenTextSplitter(chunk_size=2000, chunk_overlap=50)\n",
    "\n",
    "chunks = token_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Documents split into {len(chunks)} chunks\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5989d27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "summary_chain_refine = load_summarize_chain(\n",
    "    ChatOpenAI(temperature=0.0), \n",
    "    chain_type=\"refine\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_refine = summary_chain_refine(chunks, callbacks=[totals_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07d2380",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(summary_refine[\"output_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ed480",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(totals_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad7cdc4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
