{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a4b18d",
   "metadata": {},
   "source": [
    "# Working with Web pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaa10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from IPython.display import display, HTML, Markdown\n",
    "from pprint import pprint\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05aff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import OpenAICallbackHandler\n",
    "\n",
    "totals_cb = OpenAICallbackHandler()\n",
    "\n",
    "print(totals_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde7342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "pages=[\n",
    "    \"https://yoshuabengio.org/2023/06/24/faq-on-catastrophic-ai-risks/\", # total tokens used - ca. 14k\n",
    "    \"https://openai.com/research/instruction-following\", # total tokens used - ca. 5k\n",
    "    \"https://blog.langchain.dev/announcing-langsmith/\", # total tokens used - ca. 3k\n",
    "]\n",
    "\n",
    "loader = WebBaseLoader(pages[0])\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"Document has {len(docs)} pages\\n\")\n",
    "pprint(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3851786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "total_tokens = 0\n",
    "for n, page in enumerate(docs):\n",
    "    tokens = llm.get_num_tokens(page.page_content)\n",
    "    total_tokens += tokens\n",
    "    print(f\"Page {n+1:2d}: {tokens:>}\")\n",
    "    \n",
    "print(f\"Total number of tokens in document: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8100ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(        \n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 3000,\n",
    "    chunk_overlap  = 0,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Documents split into {len(chunks)} chunks\\n\")\n",
    "pprint(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cc54a2",
   "metadata": {},
   "source": [
    "Check **LangChain**'s API reference on [text splitters](https://api.python.langchain.com/en/latest/api_reference.html#module-langchain.text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce79135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "token_splitter = TokenTextSplitter(chunk_size=2000, chunk_overlap=50)\n",
    "\n",
    "chunks = token_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Documents split into {len(chunks)} chunks\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f96f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "summary_chain_refine = load_summarize_chain(\n",
    "    ChatOpenAI(temperature=0.0), \n",
    "    chain_type=\"refine\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c4fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_refine = summary_chain_refine(chunks, callbacks=[totals_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb8d5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(summary_refine[\"output_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff47ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(totals_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57430d80",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
