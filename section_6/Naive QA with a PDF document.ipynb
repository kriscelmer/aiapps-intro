{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbf17beb",
   "metadata": {},
   "source": [
    "# Naive QA with a PDF document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a17cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from IPython.display import display, HTML, Markdown\n",
    "from pprint import pprint\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e58fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import OpenAICallbackHandler\n",
    "\n",
    "totals_cb = OpenAICallbackHandler()\n",
    "\n",
    "print(totals_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e517ff",
   "metadata": {},
   "source": [
    "## Mind the costs!!!\n",
    "\n",
    "This notebook performs many requests to OpenAI LLM endpoints with very large count of tokens.\n",
    "\n",
    "Running it with latest and greatest models may cost several $ per one question answered!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69372fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "paper = \"https://arxiv.org/pdf/2304.00612.pdf\" # total tokens used - ca. 25k\n",
    "\n",
    "loader = PyPDFLoader(paper)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"Document has {len(docs)} pages\\n\")\n",
    "pprint(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70669143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "qa_chain = load_qa_chain(\n",
    "    ChatOpenAI(temperature=0.0), \n",
    "    chain_type=\"map_reduce\", \n",
    "    return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0495cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(qa_chain.llm_chain.prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a1b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(qa_chain.combine_document_chain.llm_chain.prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77deed47",
   "metadata": {},
   "source": [
    "### Summary from `refine` chain:\n",
    "\n",
    "This paper discusses eight important points about large language models (LLMs), including their increasing capabilities with investment, the emergence of unpredictable behaviors, their ability to learn and use representations of the outside world, the lack of reliable techniques for controlling their behavior, the limited understanding of how LLMs work, their performance surpassing human limitations, their potential misalignment with the values of their creators, and the potential for misleading interactions. The paper emphasizes the need for informed discussions and decision-making about LLMs and highlights concerns and opinions regarding the risks and failures of advanced AI systems. The new context provided further emphasizes the challenges in interpreting LLMs, their potential to outperform humans, the control developers have over their values, and the need for safety measures and governance mechanisms in large-scale LLM training. The paper also acknowledges the immaturity of the science and scholarship around LLMs, the need to separate debates about language understanding and agency from the discussed issues, and the broader value judgments surrounding LLMs that go beyond the scope of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0ab8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me more about the potential of LLMs to outperform humans\"\n",
    "\n",
    "response = qa_chain(\n",
    "    {\"input_documents\": docs, \"question\": question}, \n",
    "    callbacks=[totals_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a26f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response[\"intermediate_steps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e0ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response[\"output_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb836603",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(totals_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c201b8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
