{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3b1fd8",
   "metadata": {},
   "source": [
    "# Chat conversation memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44819de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from IPython.display import display, HTML, Markdown\n",
    "from pprint import pprint\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12534a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import OpenAICallbackHandler\n",
    "\n",
    "totals_cb = OpenAICallbackHandler()\n",
    "\n",
    "print(totals_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de60c268",
   "metadata": {},
   "source": [
    "### Chain with `ConversationBufferMemory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b608a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "template = \"\"\"\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "AI: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], template=template\n",
    ")\n",
    "\n",
    "llm_chain_with_memory = LLMChain(\n",
    "    llm=ChatOpenAI(temperature=0.0),\n",
    "    prompt=prompt,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "get_chat_response = lambda x: llm_chain_with_memory(x, callbacks=[totals_cb])['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe1c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_chat_response(\"What is the most popular container data structure in Python?\")\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc359e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_chat_response(\"Tell me more about it\")\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c1096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cd41be",
   "metadata": {},
   "source": [
    "### Initializing buffer memory with messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04597d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "memory.save_context({\"input\": \"Be brief\"}, {\"output\": \"OK\"})\n",
    "\n",
    "pprint(memory.chat_memory.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2e3ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1712c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "AI: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], template=template\n",
    ")\n",
    "\n",
    "llm_chain_with_memory = LLMChain(\n",
    "    llm=ChatOpenAI(temperature=0.0),\n",
    "    prompt=prompt,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "get_response = lambda x: llm_chain_with_memory(x, callbacks=[totals_cb])['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf8ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(\"What is the most popular container data structure in Python?\")\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9679f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(\"Tell me more about it\")\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e62a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277ef4e3",
   "metadata": {},
   "source": [
    "### `ConversationChain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7772b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "conversation_chain = ConversationChain(\n",
    "    llm=ChatOpenAI(temperature=0.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3f8f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(conversation_chain.prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7b3769",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pprint(conversation_chain.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4522b175",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = conversation_chain(\"How to split Python string?\", callbacks=[totals_cb])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05e3af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response[\"response\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf4f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response = lambda x: conversation_chain(x, callbacks=[totals_cb])['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0724f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_response(\"Can delimiter be a multi-character string, like 'stop'?\")\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e4afa3",
   "metadata": {},
   "source": [
    "### `ConversationBufferMemory` customization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731d3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_memory = ConversationBufferMemory(\n",
    "    human_prefix=\"Q\",\n",
    "    ai_prefix=\"A\"\n",
    ")\n",
    "\n",
    "my_memory.save_context({\"input\": \"Be brief\"}, {\"output\": \"OK\"})\n",
    "\n",
    "print(my_memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fe420b",
   "metadata": {},
   "source": [
    "### Clear chat memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464c9d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_memory.clear()\n",
    "\n",
    "pprint(my_memory.chat_memory.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f5dee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7844fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(totals_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61af045f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
