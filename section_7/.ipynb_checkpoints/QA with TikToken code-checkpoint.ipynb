{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d476c87a",
   "metadata": {},
   "source": [
    "# QA with TikToken code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58588a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from IPython.display import display, HTML, Markdown\n",
    "from pprint import pprint\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0083824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import OpenAICallbackHandler\n",
    "\n",
    "totals_cb = OpenAICallbackHandler()\n",
    "\n",
    "print(totals_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3f6cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./tiktoken\n",
    "!git clone https://github.com/openai/tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e96e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "root_dir = 'tiktoken'\n",
    "chunks = []\n",
    "\n",
    "# Go through each folder\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    \n",
    "    # Go through each file\n",
    "    for file in filenames:\n",
    "        try: \n",
    "            # Load the file and split\n",
    "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
    "            chunks += loader.load_and_split()\n",
    "        except Exception as e: \n",
    "            pass\n",
    "\n",
    "\n",
    "print (f\"There are {len(chunks)} chunks\\n\")\n",
    "print (chunks[0].page_content[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46dc1e2-d556-4048-b83f-3aa52cd6cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./chroma_db/tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell only to create a Vector DB from scratch\n",
    "# Skip it if persisted DB already exists\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"multi-qa-MiniLM-L6-cos-v1\")\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "    chunks, \n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db/tiktoken\"\n",
    ") # takes few minutes\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"multi-qa-MiniLM-L6-cos-v1\")\n",
    "\n",
    "db = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_db/tiktoken\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d624e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=db.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a81ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Give me example code to count tokens in a text\"\n",
    "\n",
    "result = qa_chain({\"query\": question}, callbacks=[totals_cb])\n",
    "\n",
    "display(Markdown(result[\"result\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f78d3d6-ca16-4928-8c24-942ac5f8f9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Load the encoding for the desired model\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "def count_tokens(text):\n",
    "    # Encode the text into tokens\n",
    "    tokens = enc.encode(text)\n",
    "\n",
    "    # Count the number of tokens\n",
    "    num_tokens = len(tokens)\n",
    "\n",
    "    return num_tokens\n",
    "\n",
    "# Example usage\n",
    "text = \"Hello, world! This is an example text.\"\n",
    "num_tokens = count_tokens(text)\n",
    "print(\"Number of tokens:\", num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef600a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(result[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c796798",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How to get encoding for specific model?\"\n",
    "\n",
    "result = qa_chain({\"query\": question}, callbacks=[totals_cb])\n",
    "\n",
    "display(Markdown(result[\"result\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d18efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What encoding_for_model does?\"\n",
    "\n",
    "result = qa_chain({\"query\": question}, callbacks=[totals_cb])\n",
    "\n",
    "display(Markdown(result[\"result\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9abc2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(totals_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b288f95c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
