{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb3baf2c",
   "metadata": {},
   "source": [
    "# Using LangChain library to interact with OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc87884",
   "metadata": {},
   "source": [
    "Import `openai` library and set up environment variable `OPENAI_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb742225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e2258",
   "metadata": {},
   "source": [
    "Import and set up *text completion* model from *LangChain*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9d00a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "# LangChain OpenAI reference: https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html\n",
    "\n",
    "text_llm = OpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522c52b1",
   "metadata": {},
   "source": [
    "Create a simple prompt and get a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f16e42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt = \"Explain a Python concept of a list in one paragraph\"\n",
    "\n",
    "response = text_llm(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f98fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain a Python concept of a list comprehension in one paragraph\"\n",
    "\n",
    "response = text_llm(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc58f410",
   "metadata": {},
   "source": [
    "## Text vs Chat Models\n",
    "\n",
    "Text models implemented by `langchain.OpenAI(...)` call `/v1/completions` endpoint.\n",
    "\n",
    "Chat models implemented by `langchain.chat_models.ChatOpenAI(...)` call `/v1/chat/completions`.\n",
    "\n",
    "Check [OpenAI Model Compatibility](https://platform.openai.com/docs/models/model-endpoint-compatibility) for Text and Chat model names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c38a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_llm.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f2a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = \"Hi there\"\n",
    "\n",
    "output_string = text_llm(input_string)\n",
    "\n",
    "type(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f531808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatOpenAI reference doc: https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat_llm = ChatOpenAI(temperature=0.0)\n",
    "\n",
    "print(chat_llm.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be7e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from langchain.schema import (\n",
    "    SystemMessage, # 1st message - general instructions, output format description, some context\n",
    "    HumanMessage, # user message - question or task, optional additional context\n",
    "    AIMessage # AI response\n",
    ")\n",
    "\n",
    "input_messages = [\n",
    "    HumanMessage(\n",
    "        content=\"Explain a Python concept of a list in one paragraph\"\n",
    "    )\n",
    "]\n",
    "\n",
    "output_message = chat_llm(input_messages)\n",
    "\n",
    "print(f\"type(output_message) is {type(output_message)}\\n\")\n",
    "\n",
    "pprint(output_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee5cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd94d74",
   "metadata": {},
   "source": [
    "### Copy-paste Chat completion function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adebc3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "def get_response(prompt: str, temperature=0.0) -> str:\n",
    "    chat_llm = ChatOpenAI(temperature=temperature)\n",
    "    input_messages = [HumanMessage(content=prompt)]\n",
    "\n",
    "    output_message = chat_llm(input_messages)\n",
    "    \n",
    "    return output_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689a8f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = \"Explain a Python concept of a list in one paragraph\"\n",
    "\n",
    "output_string = get_response(input_string)\n",
    "\n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8ace2",
   "metadata": {},
   "source": [
    "### Cost of Text vs Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93afca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "question = \"Explain a Python concept of a data class in one paragraph\"\n",
    "\n",
    "with get_openai_callback() as cb_t:\n",
    "    text_response = text_llm(question)\n",
    "    \n",
    "print(f\"Text completion:\\n{text_response}\\n\")\n",
    "\n",
    "with get_openai_callback() as cb_c:\n",
    "    chat_response = chat_llm([HumanMessage(content=question)])\n",
    "    \n",
    "print(f\"Chat completion:\\n{chat_response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f64c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Text completion\\n\", cb_t)\n",
    "print(\"\\nChat completion\\n\", cb_c)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Text completions is {cb_t.total_cost / cb_c.total_cost :.1f} more expensive than Chat completion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd6d39b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
